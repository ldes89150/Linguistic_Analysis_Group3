{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 3 Discussion Log\n",
    "\n",
    "**Members**: Gilbert Shih (施中右), Mipanox Chou (周炫谷), Shao-Man Lee (李韶曼) <br>\n",
    "**Time**: 2015/10/31 - 11/03<br>\n",
    "**Topics**:<br>\n",
    "1. Subject of the project: what kind of texts?<br>\n",
    "1. Preliminary tasks: source and retrieval of the texts<br>\n",
    "1. Future plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Subject: Politics\n",
    "- #### What is politics?<br>\n",
    " Our definition: Anything relevant to people is politics !<br>\n",
    " In particular, we want to study the politics of the judicial Yuan - The *Honorable Justices* (大法官).<br>\n",
    " \n",
    "- #### Background:<br>\n",
    " Shao-Man is a graduate student in the department of law.<br>\n",
    " She wants to analyze the **Interpretations** (解釋文), as well as **Opinions**(意見書), **Reasonings**(理由書) of the *Honorable Justices*<br>\n",
    " \n",
    " There are over 732 Interpretations and hundreds of Opinions and Reasonings now, all of which are pulicaly available.<br>\n",
    " \n",
    "- #### Problems of the current state of Cnstitutional Court:<br>\n",
    " In the process of writing an Interpertation or others, people generally have no idea who the *author* is, except for the members of the counsil.<br>\n",
    " 1. The general public often finds it arduous apprehending the meaning of those documents.<br>\n",
    " 1. The Honorable Justices do not care about responsibility - they are inclined to write without much deliberation. Thus the Opinions and Reasonings may lack compelling arguments.\n",
    "\n",
    "- #### Topics to study:<br>\n",
    " To solve the problems addressed above, we may try<br>\n",
    " 1. to test, if there is any, certain writing styles of the opinions of the Constitutional Court<br>\n",
    " 1. whether it is possible to identify which justice is the author of a judgment based only on the writing style<br>\n",
    " \n",
    " In this way, the justices, whose identities are revealed, might discuss more carefully.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Tasks:\n",
    "- #### Possible difficulties:<br>\n",
    " 1. Some justices might not have written any of the documents.<br>\n",
    "   - There is no way to identify a *new* style from the corpus.<br>\n",
    " 1. Most *Opinions* are in pdf format, some are even scanned images.<br>\n",
    "   - We need to parse those documents manually.<br>\n",
    " 1. The words used in the documents are often jargons that are distinct from common expressions.<br>\n",
    "   - So that our knowledge of colloquial usages etc. cannot be applied.\n",
    "\n",
    "- #### What we can do: <br>\n",
    " 1. Segmentations and parts of speech:<br>\n",
    "   - These can be readily done using the libraries in R<br>\n",
    "   \n",
    " 1. Style identification:<br>\n",
    "   - Select words that are unrelated to topics (e.g. conjunctions, prepositions, adjectives, etc.).<br>\n",
    "     *Reference: Rosenthal and Yoon [2011](http://arxiv.org/pdf/1104.2974v1.pdf)*<br>\n",
    "   - Analyze the frequencies, locations of those words<br>\n",
    " \n",
    " Once the texts are 'dissected' into pieces of information such as vectors and numeric data, we can feed them into **machine learning** codes to train computers to recognize the authorship.\n",
    "   \n",
    "- #### What we have done: <br>\n",
    " 1. Retrieval of *Interpretations*<br>\n",
    "   - These documents are present as pure texts on the [webpage](http://www.judicial.gov.tw/constitutionalcourt/p03.asp) of the *Judical Yuan*.<br>\n",
    "   \n",
    "   - We use Python to fetch parts of the complete document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class parser():\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "        self.d = dict()\n",
    "    \n",
    "    def fetch(self,n):\n",
    "        r = requests.get(\"http://www.judicial.gov.tw/constitutionalcourt/p03_01_printpage.asp?expno={0}\".format(n))\n",
    "        self.tree = html.fromstring(r.content.decode(\"big5\"))\n",
    "        self.d = dict()\n",
    "        i = 1\n",
    "        while True:\n",
    "            try:\n",
    "                key =  self.tree.xpath(\"/html/body/center/table/tr/td/table/tr[2]/td/table/tr[{0}]/td[{1}]\".format(i,1))[0].text_content()\n",
    "                value =  self.tree.xpath(\"/html/body/center/table/tr/td/table/tr[2]/td/table/tr[{0}]/td[{1}]\".format(i,2))[0].text_content()\n",
    "                self.d[key]=value\n",
    "                i+=1\n",
    "            except IndexError:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=parser()\n",
    "p.fetch(733) # 解釋字號\n",
    "print(p.d['解釋文']) #For python 2 users, this should be print(p.d[u'解釋文'])\n",
    "print(p.d['理由書'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future plan:\n",
    "- #### Questions:\n",
    " 1. How to process image file<br>\n",
    "   - So far we do not know how to extract texts from pdf files (including scanned ones)<br>\n",
    "   \n",
    " 1. Nonsense in the processed data?<br>\n",
    "   - The removal of 'topic relevant' words may result in something like this:<br>\n",
    "   \n",
    "        ***的的的***\n",
    "        \n",
    "     We would lose the information of the original usage if we discard the words in between.<br>\n",
    "     \n",
    " 1. Evolution of the language:<br>\n",
    "   - During the past decades, the popular expressions must have changed. In this case, the variability (and hence unpredictability) of the language itself adds nothing but more complexities.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
